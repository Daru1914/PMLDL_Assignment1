{"metadata":{"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### paraGeDi  \n\nIn this notebook we will be performing the detoxification task using the paraGeDi model from https://github.com/s-nlp/detox/tree/main:","metadata":{}},{"cell_type":"code","source":"%pip install -r /kaggle/input/sdfsdfsfsd/requirements.txt -q","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:01:19.883438Z","iopub.execute_input":"2023-11-05T15:01:19.884360Z","iopub.status.idle":"2023-11-05T15:01:32.195971Z","shell.execute_reply.started":"2023-11-05T15:01:19.884321Z","shell.execute_reply":"2023-11-05T15:01:32.194817Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ndataset = pd.read_csv(\"/kaggle/input/qwertyy/separated_tox.csv\")\ndataset = dataset.set_index(dataset.columns[0])\ndataset.index.name = \"Index\"\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:02:27.373631Z","iopub.execute_input":"2023-11-05T15:02:27.374041Z","iopub.status.idle":"2023-11-05T15:02:29.659337Z","shell.execute_reply.started":"2023-11-05T15:02:27.374008Z","shell.execute_reply":"2023-11-05T15:02:29.658348Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                                   toxic  \\\nIndex                                                      \n0      if alkar floods her with her mental waste, it ...   \n1                            you're becoming disgusting.   \n2                          well, we can spare your life.   \n3                           monkey, you have to wake up.   \n4                             i have orders to kill her.   \n\n                                               non-toxic  old_toxicity  \\\nIndex                                                                    \n0      if alkar is flooding her with psychic waste, t...      0.981983   \n1                              now you're getting nasty.      0.999039   \n2               well, we could spare your life, for one.      0.985068   \n3              ah! monkey, you've got to snap out of it.      0.994215   \n4                       i've got orders to put her down.      0.999348   \n\n       new_toxicity  \nIndex                \n0          0.014195  \n1          0.065473  \n2          0.213313  \n3          0.053362  \n4          0.009402  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic</th>\n      <th>non-toxic</th>\n      <th>old_toxicity</th>\n      <th>new_toxicity</th>\n    </tr>\n    <tr>\n      <th>Index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>if alkar floods her with her mental waste, it ...</td>\n      <td>if alkar is flooding her with psychic waste, t...</td>\n      <td>0.981983</td>\n      <td>0.014195</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>you're becoming disgusting.</td>\n      <td>now you're getting nasty.</td>\n      <td>0.999039</td>\n      <td>0.065473</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>well, we can spare your life.</td>\n      <td>well, we could spare your life, for one.</td>\n      <td>0.985068</td>\n      <td>0.213313</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>monkey, you have to wake up.</td>\n      <td>ah! monkey, you've got to snap out of it.</td>\n      <td>0.994215</td>\n      <td>0.053362</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i have orders to kill her.</td>\n      <td>i've got orders to put her down.</td>\n      <td>0.999348</td>\n      <td>0.009402</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=49)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:02:33.307435Z","iopub.execute_input":"2023-11-05T15:02:33.308359Z","iopub.status.idle":"2023-11-05T15:02:33.815626Z","shell.execute_reply.started":"2023-11-05T15:02:33.308323Z","shell.execute_reply":"2023-11-05T15:02:33.814500Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport sys\n\ndef add_sys_path(p):\n    p = os.path.abspath(p)\n    print(p)\n    if p not in sys.path:\n        sys.path.append(p)\n\nadd_sys_path('/kaggle/input/parapara/paraGeDi')\nadd_sys_path('/kaggle/input/bertbert/condBERT')\n\nfrom importlib import reload\nimport condbert\nreload(condbert)\nfrom condbert import CondBertRewriter\nimport torch\nfrom transformers import BertTokenizer, BertForMaskedLM\nimport numpy as np\nimport pickle\nfrom tqdm.auto import tqdm, trange\ndevice = torch.device('cuda:0')","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:02:35.859192Z","iopub.execute_input":"2023-11-05T15:02:35.859915Z","iopub.status.idle":"2023-11-05T15:02:41.500203Z","shell.execute_reply.started":"2023-11-05T15:02:35.859881Z","shell.execute_reply":"2023-11-05T15:02:41.499207Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/input/parapara/paraGeDi\n/kaggle/input/bertbert/condBERT\n","output_type":"stream"}]},{"cell_type":"code","source":"os.environ['CUDA_VISIBLE_DEVICES'] = '0'\nimport torch\nimport numpy as np\nfrom importlib import reload\nimport gedi_adapter\nreload(gedi_adapter)\nfrom gedi_adapter import GediAdapter\n\nfrom transformers import AutoModelForSeq2SeqLM, AutoModelForCausalLM, AutoTokenizer\nt5name = 'SkolkovoInstitute/t5-paraphrase-paws-msrp-opinosis-paranmt'\nimport sys\nsys.path.append(os.path.abspath('../transfer_utils/'))\n\nimport text_processing\nreload(text_processing);","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:02:44.645539Z","iopub.execute_input":"2023-11-05T15:02:44.646436Z","iopub.status.idle":"2023-11-05T15:02:44.665253Z","shell.execute_reply.started":"2023-11-05T15:02:44.646399Z","shell.execute_reply":"2023-11-05T15:02:44.664316Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(t5name)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:02:47.311554Z","iopub.execute_input":"2023-11-05T15:02:47.312524Z","iopub.status.idle":"2023-11-05T15:02:48.638739Z","shell.execute_reply.started":"2023-11-05T15:02:47.312471Z","shell.execute_reply":"2023-11-05T15:02:48.637701Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"para = AutoModelForSeq2SeqLM.from_pretrained(t5name)\npara.resize_token_embeddings(len(tokenizer)) ","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:02:50.963129Z","iopub.execute_input":"2023-11-05T15:02:50.963521Z","iopub.status.idle":"2023-11-05T15:02:54.790561Z","shell.execute_reply.started":"2023-11-05T15:02:50.963490Z","shell.execute_reply":"2023-11-05T15:02:54.789737Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Embedding(32100, 768)"},"metadata":{}}]},{"cell_type":"code","source":"model_path = 'SkolkovoInstitute/gpt2-base-gedi-detoxification'\ngedi_dis = AutoModelForCausalLM.from_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:02:57.135895Z","iopub.execute_input":"2023-11-05T15:02:57.136795Z","iopub.status.idle":"2023-11-05T15:03:02.357645Z","shell.execute_reply.started":"2023-11-05T15:02:57.136759Z","shell.execute_reply":"2023-11-05T15:03:02.356796Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at SkolkovoInstitute/gpt2-base-gedi-detoxification were not used when initializing GPT2LMHeadModel: ['logit_scale', 'bias']\n- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"NEW_POS = tokenizer.encode('normal', add_special_tokens=False)[0]\nNEW_NEG = tokenizer.encode('toxic', add_special_tokens=False)[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:03:08.238773Z","iopub.execute_input":"2023-11-05T15:03:08.239681Z","iopub.status.idle":"2023-11-05T15:03:08.246377Z","shell.execute_reply.started":"2023-11-05T15:03:08.239636Z","shell.execute_reply":"2023-11-05T15:03:08.245338Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# add gedi-specific parameters\nif os.path.exists(model_path):\n    w = torch.load(model_path + '/pytorch_model.bin', map_location='cpu')\n    gedi_dis.bias = w['bias']\n    gedi_dis.logit_scale = w['logit_scale']\n    del w\nelse:\n    gedi_dis.bias = torch.tensor([[ 0.08441592, -0.08441573]])\n    gedi_dis.logit_scale = torch.tensor([[1.2701858]])\nprint(gedi_dis.bias, gedi_dis.logit_scale)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:03:11.025544Z","iopub.execute_input":"2023-11-05T15:03:11.026029Z","iopub.status.idle":"2023-11-05T15:03:11.036793Z","shell.execute_reply.started":"2023-11-05T15:03:11.025988Z","shell.execute_reply":"2023-11-05T15:03:11.035380Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"tensor([[ 0.0844, -0.0844]]) tensor([[1.2702]])\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n\ndadapter = GediAdapter(model=para, gedi_model=gedi_dis, tokenizer=tokenizer, gedi_logit_coef=5, target=1, neg_code=NEW_NEG, pos_code=NEW_POS, lb=None, ub=None)\ntext = 'The internal policy of Trump is flawed.'\nprint('====BEFORE====')\nprint(text)\nprint('====AFTER=====')\ninputs = tokenizer.encode(text, return_tensors='pt').to(para.device)\nresult = dadapter.generate(inputs, do_sample=True, num_return_sequences=3, temperature=1.0, repetition_penalty=3.0, num_beams=1)\nfor r in result:\n    print(tokenizer.decode(r, skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:03:13.803164Z","iopub.execute_input":"2023-11-05T15:03:13.804037Z","iopub.status.idle":"2023-11-05T15:03:19.618513Z","shell.execute_reply.started":"2023-11-05T15:03:13.803999Z","shell.execute_reply":"2023-11-05T15:03:19.617575Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"====BEFORE====\nThe internal policy of Trump is flawed.\n====AFTER=====\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"the president’s narcisses domestic policy is flawed.\nthe president is a fraud.\nthe president is a failure in his internal policy.\nCPU times: user 11.4 s, sys: 41.3 ms, total: 11.5 s\nWall time: 5.81 s\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\ndevice = torch.device('cuda:0')\n# device = torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:03:51.223719Z","iopub.execute_input":"2023-11-05T15:03:51.224570Z","iopub.status.idle":"2023-11-05T15:03:51.228784Z","shell.execute_reply.started":"2023-11-05T15:03:51.224534Z","shell.execute_reply":"2023-11-05T15:03:51.227856Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import gc\n\ndef cleanup():\n    gc.collect()\n    if torch.cuda.is_available() and device.type != 'cpu':\n        with torch.cuda.device(device):\n            torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:17:35.306478Z","iopub.execute_input":"2023-11-05T15:17:35.306886Z","iopub.status.idle":"2023-11-05T15:17:35.312782Z","shell.execute_reply.started":"2023-11-05T15:17:35.306855Z","shell.execute_reply":"2023-11-05T15:17:35.311724Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"para.to(device);\npara.eval();","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:04:08.319247Z","iopub.execute_input":"2023-11-05T15:04:08.320233Z","iopub.status.idle":"2023-11-05T15:04:12.986220Z","shell.execute_reply.started":"2023-11-05T15:04:08.320185Z","shell.execute_reply":"2023-11-05T15:04:12.985411Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"gedi_dis.to(device);\ngedi_dis.bias = gedi_dis.bias.to(device)\ngedi_dis.logit_scale = gedi_dis.logit_scale.to(device)\ngedi_dis.eval();","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:04:20.544040Z","iopub.execute_input":"2023-11-05T15:04:20.544413Z","iopub.status.idle":"2023-11-05T15:04:20.955765Z","shell.execute_reply.started":"2023-11-05T15:04:20.544383Z","shell.execute_reply":"2023-11-05T15:04:20.954955Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Let's test the paraGeDi on samples from our dataset:","metadata":{}},{"cell_type":"code","source":"test_data = [line.strip() for line in test_dataset[\"toxic\"]]\nprint(len(test_data))","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:12:45.526404Z","iopub.execute_input":"2023-11-05T15:12:45.527292Z","iopub.status.idle":"2023-11-05T15:12:45.578327Z","shell.execute_reply.started":"2023-11-05T15:12:45.527250Z","shell.execute_reply":"2023-11-05T15:12:45.577324Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"115556\n","output_type":"stream"}]},{"cell_type":"code","source":"dadapter = GediAdapter(\n    model=para, gedi_model=gedi_dis, tokenizer=tokenizer, gedi_logit_coef=10, target=0, neg_code=NEW_NEG, pos_code=NEW_POS, \n    reg_alpha=3e-5, ub=0.01\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:13:07.565603Z","iopub.execute_input":"2023-11-05T15:13:07.566487Z","iopub.status.idle":"2023-11-05T15:13:07.572476Z","shell.execute_reply.started":"2023-11-05T15:13:07.566424Z","shell.execute_reply":"2023-11-05T15:13:07.571061Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def paraphrase(text, n=None, max_length='auto', beams=2):\n    texts = [text] if isinstance(text, str) else text\n    texts = [text_processing.text_preprocess(t) for t in texts]\n    inputs = tokenizer(texts, return_tensors='pt', padding=True)['input_ids'].to(dadapter.device)\n    if max_length == 'auto':\n        max_length = min(int(inputs.shape[1] * 1.1) + 4, 64)\n    result = dadapter.generate(\n        inputs, \n        num_return_sequences=n or 1, \n        do_sample=False, temperature=0.0, repetition_penalty=3.0, max_length=max_length,\n        bad_words_ids=[[2]],  # unk\n        num_beams=beams,\n    )\n    texts = [tokenizer.decode(r, skip_special_tokens=True) for r in result]\n    texts = [text_processing.text_postprocess(t) for t in texts]\n    if not n and isinstance(text, str):\n        return texts[0]\n    return texts","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:13:22.196298Z","iopub.execute_input":"2023-11-05T15:13:22.197274Z","iopub.status.idle":"2023-11-05T15:13:22.207541Z","shell.execute_reply.started":"2023-11-05T15:13:22.197230Z","shell.execute_reply":"2023-11-05T15:13:22.206495Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"paraphrase(test_data[:3])","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:13:30.135022Z","iopub.execute_input":"2023-11-05T15:13:30.135761Z","iopub.status.idle":"2023-11-05T15:13:32.741012Z","shell.execute_reply.started":"2023-11-05T15:13:30.135726Z","shell.execute_reply":"2023-11-05T15:13:32.740054Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[\"Because I'm a fist-in-the-machine!\",\n \"Walter. You'll make a lot of noise.\",\n \"What's great about life?\"]"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import RobertaForSequenceClassification, RobertaTokenizer\nclf_name = 'SkolkovoInstitute/roberta_toxicity_classifier_v1'\nclf = RobertaForSequenceClassification.from_pretrained(clf_name).to(device);\nclf_tokenizer = RobertaTokenizer.from_pretrained(clf_name)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:14:26.033585Z","iopub.execute_input":"2023-11-05T15:14:26.034283Z","iopub.status.idle":"2023-11-05T15:14:48.253236Z","shell.execute_reply.started":"2023-11-05T15:14:26.034250Z","shell.execute_reply":"2023-11-05T15:14:48.252177Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/530 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02215699c4df4024bb9b30e016e424c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78ae9886bbb04fb0bb34bdbf37c4c01f"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier_v1 were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fc4be83d8b44759820fac1c63fe9ece"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"764b6e1a11d549b38d6d77771347a759"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c58297ec40644a7835116a9603dbfbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a51687ef7de4c1d8dbda716d05fefec"}},"metadata":{}}]},{"cell_type":"code","source":"def predict_toxicity(texts):\n    with torch.inference_mode():\n        inputs = clf_tokenizer(texts, return_tensors='pt', padding=True).to(clf.device)\n        out = torch.softmax(clf(**inputs).logits, -1)[:, 1].cpu().numpy()\n    return out","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:14:58.576255Z","iopub.execute_input":"2023-11-05T15:14:58.577479Z","iopub.status.idle":"2023-11-05T15:14:58.583577Z","shell.execute_reply.started":"2023-11-05T15:14:58.577409Z","shell.execute_reply":"2023-11-05T15:14:58.582647Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"predict_toxicity(['hello world', 'hello aussie', 'hello fucking bitch'])","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:15:07.310843Z","iopub.execute_input":"2023-11-05T15:15:07.311671Z","iopub.status.idle":"2023-11-05T15:15:07.335389Z","shell.execute_reply.started":"2023-11-05T15:15:07.311622Z","shell.execute_reply":"2023-11-05T15:15:07.334492Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"array([5.052513e-05, 8.788534e-05, 9.996809e-01], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"# reload(gedi_adapter)\nfrom gedi_adapter import GediAdapter\n\n\nadapter2 = GediAdapter(\n    model=para, gedi_model=gedi_dis, tokenizer=tokenizer, \n    gedi_logit_coef=10, \n    target=0, pos_code=NEW_POS, \n    neg_code=NEW_NEG,\n    reg_alpha=3e-5,\n    ub=0.01,\n    untouchable_tokens=[0, 1],\n)\n\n\ndef paraphrase(text, max_length='auto', beams=5, rerank=True):\n    texts = [text] if isinstance(text, str) else text\n    texts = [text_processing.text_preprocess(t) for t in texts]\n    inputs = tokenizer(texts, return_tensors='pt', padding=True)['input_ids'].to(adapter2.device)\n    if max_length == 'auto':\n        max_length = min(int(inputs.shape[1] * 1.1) + 4, 64)\n    attempts = beams\n    out = adapter2.generate(\n        inputs, \n        num_beams=beams,\n        num_return_sequences=attempts, \n        do_sample=False, \n        temperature=1.0, \n        repetition_penalty=3.0, \n        max_length=max_length,\n        bad_words_ids=[[2]],  # unk\n        output_scores=True, \n        return_dict_in_generate=True,\n    )\n    results = [tokenizer.decode(r, skip_special_tokens=True) for r in out.sequences]\n\n    if rerank:\n        scores = predict_toxicity(results)\n    \n    results = [text_processing.text_postprocess(t) for t in results]\n    out_texts = []\n    for i in range(len(texts)):\n        if rerank:\n            idx = scores[(i*attempts):((i+1)*attempts)].argmin()\n        else:\n            idx = 0\n        out_texts.append(results[i*attempts+idx])\n    return out_texts\n\ntorch.manual_seed(0)\nparaphrase(['fuck you!', 'you are stupid!', 'you remind me of the chump .', 'he has to be a terrorist ! .'], beams=3)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:15:17.666781Z","iopub.execute_input":"2023-11-05T15:15:17.667588Z","iopub.status.idle":"2023-11-05T15:15:18.488206Z","shell.execute_reply.started":"2023-11-05T15:15:17.667554Z","shell.execute_reply":"2023-11-05T15:15:18.487199Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[\"Fick 'Emmy.\",\n \"You'd be wrong!\",\n \"You'll remind me of chump?\",\n 'Must be a Terrorist!']"},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 2","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:16:05.328504Z","iopub.execute_input":"2023-11-05T15:16:05.328904Z","iopub.status.idle":"2023-11-05T15:16:05.333764Z","shell.execute_reply.started":"2023-11-05T15:16:05.328873Z","shell.execute_reply":"2023-11-05T15:16:05.332516Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import os\nfrom tqdm.auto import tqdm, trange\n\ncleanup()\n\nlines = test_data[:3000]\noutputs = []\n\n\nfor i in trange(int(len(lines) / batch_size + 1)):\n    if i % 10 == 0:\n        cleanup()\n    t = i * batch_size\n    batch = [line.strip() for line in lines[t:(t+batch_size)]]\n    if not batch:\n        continue\n\n    try:\n        res = paraphrase(batch, max_length='auto', beams=10)\n    except RuntimeError:\n        print('runtime error for batch ', i)\n        try:\n            cleanup()\n            res = [paraphrase([text], max_length='auto', beams=3)[0] for text in batch]\n        except RuntimeError:\n            print('runtime error for batch ', i, 'even with batch size 1')\n            res = batch\n            cleanup()\n    for out in res:\n        outputs.append(out)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-11-05T16:04:05.251213Z","iopub.execute_input":"2023-11-05T16:04:05.251631Z","iopub.status.idle":"2023-11-05T16:45:10.535265Z","shell.execute_reply.started":"2023-11-05T16:04:05.251594Z","shell.execute_reply":"2023-11-05T16:45:10.534282Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1501 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34f22b1dd29c46eb9b46fd69034b5f72"}},"metadata":{}}]},{"cell_type":"code","source":"with open('results2.txt', 'w') as file:\n    for item in outputs:\n        file.write(\"%s\\n\" % item)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T19:43:31.536060Z","iopub.execute_input":"2023-11-05T19:43:31.536454Z","iopub.status.idle":"2023-11-05T19:43:31.564106Z","shell.execute_reply.started":"2023-11-05T19:43:31.536422Z","shell.execute_reply":"2023-11-05T19:43:31.562984Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults2.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43moutputs\u001b[49m:\n\u001b[1;32m      3\u001b[0m         file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m item)\n","\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"],"ename":"NameError","evalue":"name 'outputs' is not defined","output_type":"error"}]},{"cell_type":"code","source":"len(outputs)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T19:43:19.300379Z","iopub.execute_input":"2023-11-05T19:43:19.300803Z","iopub.status.idle":"2023-11-05T19:43:19.633023Z","shell.execute_reply.started":"2023-11-05T19:43:19.300759Z","shell.execute_reply":"2023-11-05T19:43:19.631676Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43moutputs\u001b[49m)\n","\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"],"ename":"NameError","evalue":"name 'outputs' is not defined","output_type":"error"}]}]}